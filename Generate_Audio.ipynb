{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating Audio**"
      ],
      "metadata": {
        "id": "ZfNBEbRJTVtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Introduction:**\n",
        "    - The notebook focuses on using the gTTS (Google Text-to-Speech) library to convert English and Arabic text to audio.\n",
        "    - It showcases the translation of English text into Arabic using the MarianMT model from the transformers library.\n",
        "\n",
        "2. **Requirements:**\n",
        "    - Requires installation of gTTS, transformers, and sentencepiece libraries.\n",
        "\n",
        "3. **Text-to-Speech Conversion (English):**\n",
        "    - Demonstrates the use of gTTS to convert English text to audio.\n",
        "    - English text is provided, converted to speech, and saved as \"English_audio.wav\".\n",
        "\n",
        "4. **Translation to Arabic:**\n",
        "    - Utilizes the transformers library with the MarianMT model for English to Arabic translation.\n",
        "    - The translated Arabic text is then converted to speech using gTTS and saved as \"Arabic_audio.wav\".\n",
        "  \n",
        "5. **Output Files:**\n",
        "    - Two audio files are generated: \"English_audio.wav\" and \"Arabic_audio.wav\" which will be used as in for Wav2Lip Model."
      ],
      "metadata": {
        "id": "Zulr_DeWvWGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Libraries"
      ],
      "metadata": {
        "id": "K6fQBrZVwcnB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hByI8Do5RgH4",
        "outputId": "15f5913d-bb8b-4487-e9e1-65003334eba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2023.11.17)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install gTTS\n",
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting English text to Audio"
      ],
      "metadata": {
        "id": "rnygZndgwgBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "\n",
        "English_text = \"\"\"\n",
        "The field of machine learning has transformed artificial intelligence, with notable subsets like deep learning, computer vision,\n",
        "and natural language processing. Deep learning, characterized by neural networks with multiple layers, has revolutionized computer vision,\n",
        "enabling machines to interpret visual data effectively. In Natural Language Processing, machine learning,\n",
        "including deep learning, has enhanced language-related tasks such as sentiment analysis and language translation.\n",
        "\"\"\"\n",
        "\n",
        "English_language = \"en\"\n",
        "\n",
        "gtts_object = gTTS(text = English_text,\n",
        "                  lang = English_language,\n",
        "                  slow = False)\n",
        "\n",
        "gtts_object.save(\"/content/English_audio.wav\")"
      ],
      "metadata": {
        "id": "GyOj8ftmRjur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(\"/content/English_audio.wav\")"
      ],
      "metadata": {
        "id": "U7fvE0oTRmsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translating English text to Arabic"
      ],
      "metadata": {
        "id": "KqC3j7k7wm-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer"
      ],
      "metadata": {
        "id": "dBtX5AWWRxpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(text, target_language):\n",
        "    model_name = f'Helsinki-NLP/opus-mt-en-{target_language}'\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "    model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(inputs, num_beams=4, max_length=200, early_stopping=True)\n",
        "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "H2JYoItyR0U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arabic_language = 'ar'\n",
        "Arabic_text = translate(English_text, arabic_language)\n",
        "print(Arabic_text)"
      ],
      "metadata": {
        "id": "ihWo7eu3R6SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting Arabic text to Audio"
      ],
      "metadata": {
        "id": "hWDTHbgFwslg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gtts_object = gTTS(text = Arabic_text,\n",
        "                  lang = arabic_language,\n",
        "                  slow = False)\n",
        "\n",
        "gtts_object.save(\"/content/Arabic_audio.wav\")"
      ],
      "metadata": {
        "id": "1DnSFhl9SAyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(\"/content/Arabic_audio.wav\")"
      ],
      "metadata": {
        "id": "8bNxRe6bTpeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mMyujpQ6ehzp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}